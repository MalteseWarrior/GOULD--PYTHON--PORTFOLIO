{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8tusd7NLPtY"
      },
      "outputs": [],
      "source": [
        "## Import Libraries\n",
        "import streamlit as st\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from spacy.pipeline import EntityRuler\n",
        "\n",
        "\n",
        "## ---------- Load Data From GoofyScraper.py ---------- ##\n",
        "SpongeData = pd.read_csv('spongebob_transcripts.csv')\n",
        "\n",
        "# Clear data of NaN values and empty strings\n",
        "SpongeData.dropna(inplace=True)\n",
        "\n",
        "# Remove rows where any critical field is an empty string\n",
        "SpongeData = SpongeData[\n",
        "    (SpongeData.iloc[:, 0].str.strip() != \"\") &  # Episode\n",
        "    (SpongeData.iloc[:, 1].str.strip() != \"\") &  # Character\n",
        "    (SpongeData.iloc[:, 2].str.strip() != \"\")    # Dialogue\n",
        "]\n",
        "\n",
        "SpongeData = SpongeData.astype(str)\n",
        "\n",
        "## ---------- Load the spaCy model for named entity recognition ---------- ##\n",
        "## ---------- Create Patterns for NER ---------- ##\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "# The dataframe is structured as follows:\n",
        "# Column 1: Episode Name\n",
        "# Column 2: Character Name\n",
        "# Column 3: Character Dialogue\n",
        "# Because of this the patterns will be based on this structure and through a for loop to capture every character and their dialogue\n",
        "\n",
        "patterns  = []\n",
        "\n",
        "# Episode\n",
        "for ep in SpongeData[\"ep\"].unique():\n",
        "    patterns.append({\"label\": \"EPISODE\", \"pattern\": ep})\n",
        "\n",
        "# Character\n",
        "for char in SpongeData[\"char\"].unique():\n",
        "    patterns.append({\"label\": \"CHARACTER\", \"pattern\": char})\n",
        "\n",
        "# Dialogue\n",
        "for text in SpongeData[\"text\"].unique():\n",
        "    patterns.append({\"label\": \"DIALOGUE\", \"pattern\": text})\n",
        "\n",
        "\n",
        "\n",
        "## ---------- Add Entity Ruler ----------- ##\n",
        "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "ruler.add_patterns(patterns)"
      ]
    }
  ]
}